<!DOCTYPE html>
<html lang="en">
  

<head>
<link rel="stylesheet" href="style.css">
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Josefin+Sans" rel="stylesheet">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">

<meta charset="utf-8">
<title>Claudia Noack</title>



</head>


<body>

<header> 
<p style="text-align: left;">&nbsp;</p>
<h1> <a class="h1" href="index.html"> CLAUDIA NOACK </a> </h1>
   <a href="research.html" style="color:red;" > Research </a> &nbsp &nbsp &nbsp
 <a href="teaching.html">Teaching</a>   &nbsp &nbsp &nbsp
 <a href="contact.html"> Contact </a>
   </header>




<section>
<div class="empty"> &nbsp </div>
<div>
<h3> Working Papers </h3>
<p style="text-align: left;"><span style="font-weight: bold;">Sensitivity Analysis of LATE Estimates to a Violation of the
 Monotonicity Assumption.</span>  </p>

 
<p class=ex2> 
This paper presents a method to assess 
the sensitivity of treatment effect estimates to potential violations of the monotonicity assumption. 
I propose a model in which the degree to which monotonicity is violated is measured by two sensitivity parameters: 
One determines the population size of defiers and the other treatment effect heterogeneity between compliers and defiers. 
I identify the breakdown frontier, which is the set of sensitivity parameters that imply the weakest assumptions, 
which are necessary to draw a particular empirical conclusion, e.g. the average treatment effect is positive.
 Evaluating the plausibility of these parameters allows researchers to assess the credibility of this conclusion. 
 I show how to conduct inference on these parameter estimates, where confidence sets are obtained through a bootstrap method.
  The performance of the breakdown frontier estimator is evaluated in a Monte Carlo study and illustrated in an empirical example.</p>
	&nbsp 




<p style="text-align: left;">&nbsp;</p>


<p style="text-align: justify;"><span style="font-weight: bold;">Bias-Aware Inference in Fuzzy Regression Discontinuity Designs</span> with Christoph Rothe,&nbsp; 
	August 2020, [<a href="#" target="_blank">R software</a>] [<a href="https://arxiv.org/abs/1906.04631" target="_blank">arxiv</a>]  </p>
<!--  <p style="color: gray;"> We show that the validitiy of commonly used confidence sets break down in many empirical settings. We therefore propose new confidence sets, which are valid in all relevant secnarios, easy to implement and have favorable efficiency properties.
</p>-->


<p class=ex2> The confidence intervals (CIs) commonly reported in empirical fuzzy regression
discontinuity studies are justified by theoretical arguments which assume that the running
variable is continuously distributed with positive density around the cutoff, and
that the jump in treatment probabilities at the cutoff is “large”. In this paper, we
provide new confidence sets (CSs) that do not rely on such assumptions. Their construction
is analogous to that of Anderson-Rubin CSs in the literature on instrumental
variable models. Our CSs are based on local linear regression, and are bias-aware, in
the sense that they explicitly take the possible smoothing bias into account. They
are valid under a wide range of empirically relevant conditions in which existing CIs
generally fail. These conditions include discrete running variables, donut designs, and
weak identification. But our CS also perform favorably relative to existing CIs in the
canonical setting with a continuous running variable, and can thus be used in all fuzzy
regression discontinuity applications.</p>
<p style="text-align: left;">&nbsp;</p>
</div>


</section>

</body>
</html>
